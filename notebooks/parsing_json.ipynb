{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd12f8c6-92d4-4011-bafd-b4e473cc75dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import Process, Manager, Pool\n",
    "from shared_funcs import gather_stats, merge_add_dict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd9b6245-9379-4b67-9ac8-f4dd06bd1b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunks = pd.read_json('../data/arxiv-metadata-oai-snapshot.json', lines=True, chunksize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a046cf6-77e5-4c7f-8228-13d295d17d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_authors(author_str):\n",
    "    authors = []\n",
    "    # remove noises\n",
    "    author_str = author_str.replace(\" \", \"\")\n",
    "    author_str = author_str.replace(\"\\n\", \"\")\n",
    "    parse_by_comma = author_str.split(',')\n",
    "    for a in parse_by_comma:\n",
    "        # parse by 'and'\n",
    "        authors.extend(a.split(' and '))\n",
    "    return authors\n",
    "\n",
    "def parse_categories(cat_str):\n",
    "    return cat_str\n",
    "\n",
    "def parse_year(date_str):\n",
    "    return date_str.split('-')[0]\n",
    "\n",
    "def count_name_frequencies(name_list2d):\n",
    "    # Flatten the list of lists into a single list of names\n",
    "    all_names = [name for sublist in name_list2d for name in sublist]\n",
    "    # Use Counter to count the frequency of each name\n",
    "    name_frequencies = Counter(all_names)\n",
    "    return dict(name_frequencies)\n",
    "\n",
    "def merge_add_dict(a, b):\n",
    "    return {key: a.get(key, 0) + b.get(key, 0) for key in set(a) | set(b)}\n",
    "\n",
    "def gather_stats(df):\n",
    "    intermediate_submitter_stats = dict(df['submitter'].value_counts())\n",
    "    intermediate_authors_stats = count_name_frequencies(list(map(parse_authors, df['authors'])))\n",
    "    # intermediate_authors_stats = merge_add_dict(intermediate_submitter_stats, intermediate_authors_stats)\n",
    "    intermediate_cat_stats = dict(df['categories'].value_counts())\n",
    "    intermediate_jou_stats = dict(df['journal-ref'].value_counts())\n",
    "    intermediate_year_stats = dict(df['update_date'].value_counts())\n",
    "    return intermediate_authors_stats, intermediate_cat_stats, intermediate_jou_stats, intermediate_year_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fce73d0e-f263-4a08-b63d-10e989ae208d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['journal-ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6738cfa-9d2b-40a3-8880-bf075d730e54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 50000\n",
      "aut stats =>  126443\n",
      "cat stats =>  6057\n",
      "journal stats =>  18651\n",
      "year stats =>  1968\n",
      "processed: 100000\n",
      "aut stats =>  213505\n",
      "cat stats =>  9397\n",
      "journal stats =>  37467\n",
      "year stats =>  2310\n",
      "processed: 150000\n",
      "aut stats =>  290762\n",
      "cat stats =>  12206\n",
      "journal stats =>  55162\n",
      "year stats =>  2485\n",
      "processed: 200000\n",
      "aut stats =>  356678\n",
      "cat stats =>  14714\n",
      "journal stats =>  73115\n",
      "year stats =>  2585\n",
      "processed: 250000\n",
      "aut stats =>  419290\n",
      "cat stats =>  16948\n",
      "journal stats =>  90658\n",
      "year stats =>  2660\n",
      "processed: 300000\n",
      "aut stats =>  478824\n",
      "cat stats =>  19063\n",
      "journal stats =>  107918\n",
      "year stats =>  2706\n",
      "processed: 350000\n",
      "aut stats =>  537850\n",
      "cat stats =>  21063\n",
      "journal stats =>  124995\n",
      "year stats =>  2723\n",
      "processed: 400000\n",
      "aut stats =>  594367\n",
      "cat stats =>  23034\n",
      "journal stats =>  141595\n",
      "year stats =>  2739\n",
      "processed: 450000\n",
      "aut stats =>  652348\n",
      "cat stats =>  25025\n",
      "journal stats =>  157981\n",
      "year stats =>  2754\n",
      "processed: 500000\n",
      "aut stats =>  708272\n",
      "cat stats =>  27174\n",
      "journal stats =>  174003\n",
      "year stats =>  2774\n",
      "processed: 550000\n",
      "aut stats =>  764745\n",
      "cat stats =>  29112\n",
      "journal stats =>  189831\n",
      "year stats =>  2794\n",
      "processed: 600000\n",
      "aut stats =>  821683\n",
      "cat stats =>  30949\n",
      "journal stats =>  205412\n",
      "year stats =>  2812\n",
      "processed: 650000\n",
      "aut stats =>  878998\n",
      "cat stats =>  32681\n",
      "journal stats =>  220858\n",
      "year stats =>  2830\n",
      "processed: 700000\n",
      "aut stats =>  933718\n",
      "cat stats =>  34802\n",
      "journal stats =>  235492\n",
      "year stats =>  2845\n",
      "processed: 750000\n",
      "aut stats =>  989151\n",
      "cat stats =>  37175\n",
      "journal stats =>  249862\n",
      "year stats =>  2848\n",
      "processed: 800000\n",
      "aut stats =>  1045382\n",
      "cat stats =>  39323\n",
      "journal stats =>  263760\n",
      "year stats =>  2858\n",
      "processed: 850000\n",
      "aut stats =>  1102102\n",
      "cat stats =>  41495\n",
      "journal stats =>  277384\n",
      "year stats =>  2865\n",
      "processed: 900000\n",
      "aut stats =>  1156978\n",
      "cat stats =>  43440\n",
      "journal stats =>  290495\n",
      "year stats =>  2870\n",
      "processed: 950000\n",
      "aut stats =>  1213906\n",
      "cat stats =>  45332\n",
      "journal stats =>  303044\n",
      "year stats =>  2880\n",
      "processed: 1000000\n",
      "aut stats =>  1267428\n",
      "cat stats =>  47187\n",
      "journal stats =>  315314\n",
      "year stats =>  2889\n",
      "processed: 1050000\n",
      "aut stats =>  1319791\n",
      "cat stats =>  48976\n",
      "journal stats =>  326307\n",
      "year stats =>  2895\n",
      "processed: 1100000\n",
      "aut stats =>  1370801\n",
      "cat stats =>  50736\n",
      "journal stats =>  336200\n",
      "year stats =>  2908\n",
      "processed: 1150000\n",
      "aut stats =>  1423189\n",
      "cat stats =>  52552\n",
      "journal stats =>  345531\n",
      "year stats =>  2911\n",
      "processed: 1200000\n",
      "aut stats =>  1474963\n",
      "cat stats =>  54288\n",
      "journal stats =>  354186\n",
      "year stats =>  2919\n",
      "processed: 1250000\n",
      "aut stats =>  1524592\n",
      "cat stats =>  55994\n",
      "journal stats =>  362417\n",
      "year stats =>  2920\n",
      "processed: 1300000\n",
      "aut stats =>  1574213\n",
      "cat stats =>  57608\n",
      "journal stats =>  369535\n",
      "year stats =>  2923\n",
      "processed: 1350000\n",
      "aut stats =>  1623776\n",
      "cat stats =>  59211\n",
      "journal stats =>  376395\n",
      "year stats =>  2925\n",
      "processed: 1400000\n",
      "aut stats =>  1673753\n",
      "cat stats =>  60699\n",
      "journal stats =>  381324\n",
      "year stats =>  2933\n",
      "processed: 1450000\n",
      "aut stats =>  1721957\n",
      "cat stats =>  62246\n",
      "journal stats =>  384908\n",
      "year stats =>  2940\n",
      "processed: 1500000\n",
      "aut stats =>  1775263\n",
      "cat stats =>  63682\n",
      "journal stats =>  388680\n",
      "year stats =>  3051\n",
      "processed: 1550000\n",
      "aut stats =>  1851318\n",
      "cat stats =>  63918\n",
      "journal stats =>  417719\n",
      "year stats =>  3385\n",
      "processed: 1600000\n",
      "aut stats =>  1908368\n",
      "cat stats =>  64695\n",
      "journal stats =>  438055\n",
      "year stats =>  3673\n",
      "processed: 1650000\n",
      "aut stats =>  1951578\n",
      "cat stats =>  65516\n",
      "journal stats =>  462697\n",
      "year stats =>  4206\n",
      "processed: 1700000\n",
      "aut stats =>  1987911\n",
      "cat stats =>  66343\n",
      "journal stats =>  494155\n",
      "year stats =>  4362\n",
      "processed: 1750000\n",
      "aut stats =>  2016137\n",
      "cat stats =>  66569\n",
      "journal stats =>  530329\n",
      "year stats =>  4402\n",
      "processed: 1800000\n",
      "aut stats =>  2038555\n",
      "cat stats =>  67405\n",
      "journal stats =>  566462\n",
      "year stats =>  4522\n",
      "processed: 1850000\n",
      "aut stats =>  2060447\n",
      "cat stats =>  68564\n",
      "journal stats =>  583066\n",
      "year stats =>  4740\n",
      "processed: 1900000\n",
      "aut stats =>  2102882\n",
      "cat stats =>  70368\n",
      "journal stats =>  610578\n",
      "year stats =>  4772\n",
      "processed: 1908545\n",
      "aut stats =>  2107577\n",
      "cat stats =>  70582\n",
      "journal stats =>  615089\n",
      "year stats =>  4776\n"
     ]
    }
   ],
   "source": [
    "# manager = Manager()\n",
    "\n",
    "# author_dict = manager.dict()\n",
    "# cat_dict = manager.dict()\n",
    "# year_dict = manager.dict()\n",
    "author_dict = {}\n",
    "cat_dict = {}\n",
    "journal_dict = {}\n",
    "year_dict = {}\n",
    "\n",
    "counter = 0\n",
    "for chunk in chunks:\n",
    "    df = chunk\n",
    "    intermediate_authors_stats, intermediate_cat_stats, intermediate_jou_stats, intermediate_year_stats = gather_stats(df)\n",
    "    author_dict = merge_add_dict(author_dict, intermediate_authors_stats)\n",
    "    cat_dict = merge_add_dict(cat_dict, intermediate_cat_stats)\n",
    "    journal_dict = merge_add_dict(journal_dict, intermediate_jou_stats)\n",
    "    year_dict = merge_add_dict(year_dict, intermediate_year_stats)\n",
    "    \n",
    "    \n",
    "    counter += len(df)\n",
    "    print(\"processed:\", counter)\n",
    "    print(\"aut stats => \", len(author_dict))\n",
    "    print(\"cat stats => \", len(cat_dict))\n",
    "    print(\"journal stats => \", len(journal_dict))\n",
    "    print(\"year stats => \", len(year_dict))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53f64458-03bc-4acf-8b0c-ce900f61e3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_dict(dict_data, byval=True, reverse=True):\n",
    "    if byval: idx = 1\n",
    "    else: idx = 0\n",
    "    return dict(sorted(dict_data.items(), key=lambda item: item[idx], reverse=reverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac58cdb0-6ef4-44bc-b594-ed9cdb58b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dict = sort_dict(author_dict)\n",
    "cat_dict = sort_dict(cat_dict)\n",
    "journal_dict = sort_dict(journal_dict)\n",
    "year_dict = sort_dict(year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6111e53-b068-4698-960d-1e8a7b6b32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('author.pickle', 'wb') as handle:\n",
    "    pickle.dump(author_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('cat.pickle', 'wb') as handle:\n",
    "    pickle.dump(cat_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a697e1-fde6-4406-bf49-cf281bb4f2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upto = 1000\n",
    "counter = 0\n",
    "for k, v in author_dict.items():\n",
    "    # if len(k)>30: continue\n",
    "    counter+=1\n",
    "    print(\"{:20} : {}\".format(k.replace(\"\\n\", \"\"), v))\n",
    "    if counter==upto: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e5ae7-7b60-456c-8a6c-840207dc0267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
